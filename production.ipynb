{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘ihdp_npci_1-100.train.npz’ already there; not retrieving.\n",
      "\n",
      "File ‘ihdp_npci_1-100.test.npz’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.train.npz\n",
    "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.test.npz \n",
    " \n",
    "def load_IHDP_data(training_data,testing_data,i=7):\n",
    "    with open(training_data,'rb') as trf, open(testing_data,'rb') as tef:\n",
    "        train_data=np.load(trf); test_data=np.load(tef)\n",
    "        y=np.concatenate(   (train_data['yf'][:,i],   test_data['yf'][:,i])).astype('float32') #most GPUs only compute 32-bit floats\n",
    "        t=np.concatenate(   (train_data['t'][:,i],    test_data['t'][:,i])).astype('float32')\n",
    "        x=np.concatenate(   (train_data['x'][:,:,i],  test_data['x'][:,:,i]),axis=0).astype('float32')\n",
    "        mu_0=np.concatenate((train_data['mu0'][:,i],  test_data['mu0'][:,i])).astype('float32')\n",
    "        mu_1=np.concatenate((train_data['mu1'][:,i],  test_data['mu1'][:,i])).astype('float32')\n",
    " \n",
    "        data={'x':x,'t':t,'y':y,'t':t,'mu_0':mu_0,'mu_1':mu_1}\n",
    "        data['t']=data['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension \n",
    "        data['y']=data['y'].reshape(-1,1)\n",
    "        #rescaling y between 0 and 1 often makes training of DL regressors easier\n",
    "        data['y_scaler'] = StandardScaler().fit(data['y'])\n",
    "        data['ys'] = data['y_scaler'].transform(data['y'])\n",
    " \n",
    "    return data\n",
    " \n",
    "data =load_IHDP_data(training_data='./ihdp_npci_1-100.train.npz',testing_data='./ihdp_npci_1-100.test.npz')\n",
    "\n",
    "X,y, t = data['x'], data['y'], data['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data_processed_arnaud.csv\")\n",
    "data.set_index(\"Unnamed: 0\", drop=True, inplace=True)\n",
    "data.index.name = None\n",
    "data = data.dropna()\n",
    "data\n",
    "\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "scaler = load(open('scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_cols = list(data.columns[:8])+[\"treatment\"]\n",
    "outcome = \"hospital_expire_flag\"\n",
    "treatment = \"treatment\"\n",
    "\n",
    "\n",
    "X = data[covariates_cols].to_numpy(dtype=\"float32\")\n",
    "t = scaler.transform(data[treatment].to_numpy(dtype=\"float32\").reshape(-1,1))\n",
    "y = data[outcome].to_numpy(dtype=\"float32\").reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_treatment = 10\n",
    "t = (t*(n_treatment-1)).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tarNET import tarNET\n",
    "import tensorflow as tf\n",
    "\n",
    "normalizer_layer = tf.keras.layers.Normalization(axis=None)\n",
    "normalizer_layer.adapt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = len(data)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.2 * DATASET_SIZE)\n",
    "test_size = int(0.1 * DATASET_SIZE)\n",
    "\n",
    "dataset = tf.data.Dataset.zip(\n",
    "    (tf.data.Dataset.from_tensor_slices((X, t)), tf.data.Dataset.from_tensor_slices(y))\n",
    ").shuffle(buffer_size=DATASET_SIZE, reshuffle_each_iteration=False)#batch(64)\n",
    "\n",
    "train_dataset = dataset.take(train_size).batch(batch_size)\n",
    "test_dataset = dataset.skip(train_size)\n",
    "val_dataset = test_dataset.take(val_size).batch(batch_size)\n",
    "test_dataset = test_dataset.skip(val_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the model with correct initial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.748740100791938 percent of the samples are positive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "neg, pos = np.bincount(np.concatenate([y for _, y in train_dataset]).reshape(-1).astype(\"int\"))\n",
    "\n",
    "initial_bias = tf.keras.initializers.Constant(np.log([pos/neg]))\n",
    "print(f\"{pos/neg*100} percent of the samples are positive\")\n",
    "\n",
    "model = tarNET(output_dim=1, n_treatments=10, normalizer_layer=normalizer_layer, scaler=scaler, output_bias=initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.10\n",
      "Weight for class 1: 5.32\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (neg+pos / 2.0)\n",
    "weight_for_1 = (1 / pos) * (neg+pos / 2.0)\n",
    "\n",
    "class_wts = tf.constant([weight_class_0, weight_class_1])\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/var/folders/m8/sb3p17zj07s4h28sd6njtsbw0000gn/T/ipykernel_30766/3526279808.py\", line 31, in train_step  *\n        loss_value = loss_fn(y, logits, sample_weight=class_weight)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/losses.py\", line 142, in __call__  **\n        return losses_utils.compute_weighted_loss(\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/losses_utils.py\", line 314, in compute_weighted_loss\n        sample_weight = tf.convert_to_tensor(sample_weight)\n\n    TypeError: Failed to convert elements of {0: 1.1037437005039596, 1: 5.319569743233865} to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000024?line=57'>58</a>\u001b[0m \u001b[39m# Iterate over the batches of the dataset.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000024?line=58'>59</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, (x_batch_train, y_batch_train) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000024?line=59'>60</a>\u001b[0m     loss_value, logits \u001b[39m=\u001b[39m train_step(x_batch_train, y_batch_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000024?line=60'>61</a>\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m batch_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000024?line=61'>62</a>\u001b[0m         loss_values\u001b[39m.\u001b[39mappend(loss_value)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1126'>1127</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1127'>1128</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1128'>1129</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1129'>1130</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1130'>1131</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/var/folders/m8/sb3p17zj07s4h28sd6njtsbw0000gn/T/ipykernel_30766/3526279808.py\", line 31, in train_step  *\n        loss_value = loss_fn(y, logits, sample_weight=class_weight)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/losses.py\", line 142, in __call__  **\n        return losses_utils.compute_weighted_loss(\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/losses_utils.py\", line 314, in compute_weighted_loss\n        sample_weight = tf.convert_to_tensor(sample_weight)\n\n    TypeError: Failed to convert elements of {0: 1.1037437005039596, 1: 5.319569743233865} to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "\n",
    "METRICS_logits = [\n",
    "    #tf.keras.metrics.BinaryAccuracy(name=\"BA\"),\n",
    "]\n",
    "\n",
    "METRICS_prob = [\n",
    "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    tf.keras.metrics.AUC(name=\"prc\", curve=\"PR\"),  # precision-recall curve\n",
    "]\n",
    "\n",
    "METRICS = METRICS_prob+METRICS_logits\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits, sample_weight=class_weight)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value, logits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    #val_probs = tf.round(tf.nn.sigmoid(val_logits))\n",
    "    \n",
    "    for m_ in METRICS:\n",
    "        m_.update_state(y, val_logits)\n",
    "        \n",
    "    #for m_ in METRICS_prob:\n",
    "        #m_.update_state(y, val_probs)\n",
    "        \n",
    "\n",
    "verbose_period=2\n",
    "epochs = 50\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    if not(epoch %verbose_period):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value, logits = train_step(x_batch_train, y_batch_train)\n",
    "        if step % batch_size == 0:\n",
    "            loss_values.append(loss_value)\n",
    "            \n",
    "        # Log every 200 batches.\n",
    "        #if step % 200 == 0:\n",
    "            #print(\n",
    "            #    \"Training loss (for one batch) at step %d: %.4f\"\n",
    "            #    % (step, float(loss_value))\n",
    "            #)\n",
    "            #print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    if not(epoch % verbose_period):\n",
    "        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "\n",
    "    #metrics logits\n",
    "    val_acc = {m_.name: m_.result().numpy() for m_ in METRICS_logits+METRICS_prob}\n",
    "    for m_ in METRICS_prob:\n",
    "        m_.reset_states()\n",
    "        \n",
    "    if not(epoch % verbose_period):\n",
    "        print(val_acc)\n",
    "    # print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    # print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "plt.plot(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8386/8386 [==============================] - ETA: 0s - loss: 0.5082 - binary_accuracy: 0.8356WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
      "8386/8386 [==============================] - 51s 6ms/step - loss: 0.5082 - binary_accuracy: 0.8356\n",
      "Epoch 2/10\n",
      "8386/8386 [==============================] - ETA: 0s - loss: 0.4707 - binary_accuracy: 0.8338WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
      "8386/8386 [==============================] - 52s 6ms/step - loss: 0.4707 - binary_accuracy: 0.8338\n",
      "Epoch 3/10\n",
      "8383/8386 [============================>.] - ETA: 0s - loss: 0.4525 - binary_accuracy: 0.8338WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
      "8386/8386 [==============================] - 66s 8ms/step - loss: 0.4524 - binary_accuracy: 0.8339\n",
      "Epoch 4/10\n",
      "8384/8386 [============================>.] - ETA: 0s - loss: 0.4609 - binary_accuracy: 0.8336WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
      "8386/8386 [==============================] - 60s 7ms/step - loss: 0.4609 - binary_accuracy: 0.8337\n",
      "Epoch 5/10\n",
      " 653/8386 [=>............................] - ETA: 1:03 - loss: 0.5303 - binary_accuracy: 0.8086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=39'>40</a>\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=42'>43</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=43'>44</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mAdam(),  \u001b[39m# SGD(learning_rate=sgd_lr, momentum=momentum, nesterov=True),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=44'>45</a>\u001b[0m     loss\u001b[39m=\u001b[39mloss,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=45'>46</a>\u001b[0m     metrics\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mBinaryAccuracy(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=46'>47</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=48'>49</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=49'>50</a>\u001b[0m     train_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=50'>51</a>\u001b[0m     \u001b[39m#x=[X,t],\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=51'>52</a>\u001b[0m     \u001b[39m#y=y,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=52'>53</a>\u001b[0m     \u001b[39m#shuffle=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=53'>54</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49madam_callbacks,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=54'>55</a>\u001b[0m     \u001b[39m#validation_split=val_split,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=55'>56</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=56'>57</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=57'>58</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=58'>59</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=60'>61</a>\u001b[0m clear_output()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000009?line=62'>63</a>\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mbinary_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1208'>1209</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1209'>1210</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1210'>1211</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1211'>1212</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1212'>1213</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1213'>1214</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1214'>1215</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1215'>1216</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1216'>1217</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py?line=1217'>1218</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=906'>907</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=908'>909</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=909'>910</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=912'>913</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=938'>939</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=939'>940</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=940'>941</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=941'>942</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=942'>943</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3126'>3127</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3127'>3128</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3128'>3129</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3129'>3130</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3130'>3131</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1954'>1955</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1955'>1956</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1956'>1957</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1957'>1958</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=600'>601</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=601'>602</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=604'>605</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=605'>606</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=606'>607</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=609'>610</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=610'>611</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "val_split = 0.2\n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "i = 0\n",
    "tf.random.set_seed(i)\n",
    "np.random.seed(i)\n",
    "\n",
    "sgd_callbacks = [\n",
    "    TerminateOnNaN(),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=40, min_delta=0.0),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"loss\",\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=verbose,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0,\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "adam_callbacks = [\n",
    "    TerminateOnNaN(),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20, min_delta=0.0),\n",
    "]\n",
    "\n",
    "# optimzier hyperparameters\n",
    "sgd_lr = 1e-5\n",
    "momentum = 0.9\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),  # SGD(learning_rate=sgd_lr, momentum=momentum, nesterov=True),\n",
    "    loss=loss,\n",
    "    metrics=tf.keras.metrics.BinaryAccuracy(),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    #x=[X,t],\n",
    "    #y=y,\n",
    "    #shuffle=True,\n",
    "    callbacks=adam_callbacks,\n",
    "    #validation_split=val_split,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "\n",
    "acc = history.history[\"binary_accuracy\"]\n",
    "val_acc = history.history[\"val_binary_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56faac8612633bcfddb99da3ad5a50bcd343e3e14a61b03833611d8357de7104"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
