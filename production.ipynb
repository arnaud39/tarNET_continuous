{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘ihdp_npci_1-100.train.npz’ already there; not retrieving.\n",
      "\n",
      "File ‘ihdp_npci_1-100.test.npz’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.train.npz\n",
    "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.test.npz \n",
    " \n",
    "def load_IHDP_data(training_data,testing_data,i=7):\n",
    "    with open(training_data,'rb') as trf, open(testing_data,'rb') as tef:\n",
    "        train_data=np.load(trf); test_data=np.load(tef)\n",
    "        y=np.concatenate(   (train_data['yf'][:,i],   test_data['yf'][:,i])).astype('float32') #most GPUs only compute 32-bit floats\n",
    "        t=np.concatenate(   (train_data['t'][:,i],    test_data['t'][:,i])).astype('float32')\n",
    "        x=np.concatenate(   (train_data['x'][:,:,i],  test_data['x'][:,:,i]),axis=0).astype('float32')\n",
    "        mu_0=np.concatenate((train_data['mu0'][:,i],  test_data['mu0'][:,i])).astype('float32')\n",
    "        mu_1=np.concatenate((train_data['mu1'][:,i],  test_data['mu1'][:,i])).astype('float32')\n",
    " \n",
    "        data={'x':x,'t':t,'y':y,'t':t,'mu_0':mu_0,'mu_1':mu_1}\n",
    "        data['t']=data['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension \n",
    "        data['y']=data['y'].reshape(-1,1)\n",
    "        #rescaling y between 0 and 1 often makes training of DL regressors easier\n",
    "        data['y_scaler'] = StandardScaler().fit(data['y'])\n",
    "        data['ys'] = data['y_scaler'].transform(data['y'])\n",
    " \n",
    "    return data\n",
    " \n",
    "data =load_IHDP_data(training_data='./ihdp_npci_1-100.train.npz',testing_data='./ihdp_npci_1-100.test.npz')\n",
    "\n",
    "X,y, t = data['x'], data['y'], data['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>wbc</th>\n",
       "      <th>lactate_cat</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>sodium</th>\n",
       "      <th>temperature</th>\n",
       "      <th>potassium</th>\n",
       "      <th>glucose</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>treatment</th>\n",
       "      <th>chf</th>\n",
       "      <th>esrd</th>\n",
       "      <th>chf.esrd</th>\n",
       "      <th>sepsis.only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>145.0</td>\n",
       "      <td>38.40</td>\n",
       "      <td>2.8</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.379091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>142.0</td>\n",
       "      <td>37.06</td>\n",
       "      <td>4.2</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.750969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>137.0</td>\n",
       "      <td>37.28</td>\n",
       "      <td>4.9</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.118877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>143.0</td>\n",
       "      <td>36.56</td>\n",
       "      <td>3.4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.550136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>134.0</td>\n",
       "      <td>35.94</td>\n",
       "      <td>4.1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.515460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14793</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>136.0</td>\n",
       "      <td>37.72</td>\n",
       "      <td>5.9</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.845730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14794</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>145.0</td>\n",
       "      <td>36.72</td>\n",
       "      <td>3.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14795</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.44</td>\n",
       "      <td>4.4</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.105659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14796</th>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>140.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>5.5</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.420172</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14797</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>142.0</td>\n",
       "      <td>36.78</td>\n",
       "      <td>3.4</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.753566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14798 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bicarbonate   wbc  lactate_cat  creatinine  sodium  temperature  \\\n",
       "0             23.0  13.3            0         0.7   145.0        38.40   \n",
       "1             28.0  17.5            0         0.8   142.0        37.06   \n",
       "2             23.0  15.1            1         1.8   137.0        37.28   \n",
       "3             17.0  27.5            0         1.2   143.0        36.56   \n",
       "4             28.0   NaN            0         0.7   134.0        35.94   \n",
       "...            ...   ...          ...         ...     ...          ...   \n",
       "14793         24.0   5.5            0         1.3   136.0        37.72   \n",
       "14794         22.0   3.7            1         0.8   145.0        36.72   \n",
       "14795         26.0   7.3            5         1.8   138.0        36.44   \n",
       "14796         14.0  15.0            1         4.8   140.0        36.33   \n",
       "14797         17.0  20.4            5         1.2   142.0        36.78   \n",
       "\n",
       "       potassium  glucose  hospital_expire_flag  treatment  chf  esrd  \\\n",
       "0            2.8    116.0                     0  22.379091    0     0   \n",
       "1            4.2    114.0                     0  15.750969    0     0   \n",
       "2            4.9    115.0                     0  26.118877    0     0   \n",
       "3            3.4    103.0                     0  13.550136    0     0   \n",
       "4            4.1    135.0                     0  18.515460    0     0   \n",
       "...          ...      ...                   ...        ...  ...   ...   \n",
       "14793        5.9    190.0                     0  13.845730    0     0   \n",
       "14794        3.5     81.0                     1   0.000000    0     0   \n",
       "14795        4.4    165.0                     1  10.105659    1     0   \n",
       "14796        5.5    224.0                     0   8.420172    1     1   \n",
       "14797        3.4    207.0                     0   8.753566    0     0   \n",
       "\n",
       "       chf.esrd  sepsis.only  \n",
       "0             0            1  \n",
       "1             0            1  \n",
       "2             0            1  \n",
       "3             0            1  \n",
       "4             0            1  \n",
       "...         ...          ...  \n",
       "14793         0            1  \n",
       "14794         0            1  \n",
       "14795         0            0  \n",
       "14796         1            0  \n",
       "14797         0            1  \n",
       "\n",
       "[14798 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data_processed_arnaud.csv\")\n",
    "data.set_index(\"Unnamed: 0\", drop=True, inplace=True)\n",
    "data.index.name = None\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "scaler = load(open('scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55202198],\n",
       "       [0.42707711],\n",
       "       [0.61041494],\n",
       "       ...,\n",
       "       [0.30661536],\n",
       "       [0.2759136 ],\n",
       "       [0.28198651]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data.treatment.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.treatment.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_cols = data.columns[:8]\n",
    "outcome = \"hospital_expire_flag\"\n",
    "treatment = \"treatment\"\n",
    "\n",
    "X = data[covariates_cols].to_numpy(dtype=\"float32\")\n",
    "t = data[treatment].to_numpy(dtype=\"float32\").reshape(-1,1)\n",
    "y = data[outcome].to_numpy(dtype=\"float32\").reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_treatment = 10\n",
    "t = (t*(n_treatment-1)).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 17:47:12.068804: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tarNET import tarNET\n",
    "import tensorflow as tf\n",
    "\n",
    "normalizer_layer = tf.keras.layers.Normalization(axis=None)\n",
    "normalizer_layer.adapt(X)\n",
    "model = tarNET(output_dim=1, n_treatments=10, normalizer_layer=normalizer_layer, scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    NotImplementedError: Exception encountered when calling layer \"tar_net\" (type tarNET).\n    \n    in user code:\n    \n        File \"/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/tarNET/models/tarNET.py\", line 76, in call  *\n            treatment_cat = tf.cast(\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\", line 2772, in transform  *\n            X = self._check_inputs(X, in_fit=False, copy=self.copy)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\", line 2702, in _check_inputs  *\n            X = self._validate_data(X, reset=in_fit,\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/base.py\", line 420, in _validate_data  *\n            X = check_array(X, **check_params)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in inner_f  *\n            return f(*args, **kwargs)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 673, in check_array  *\n            array = np.asarray(array, order=order, dtype=dtype)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/numpy/core/_asarray.py\", line 83, in asarray  **\n            return array(a, dtype, copy=False, order=order)\n    \n        NotImplementedError: Cannot convert a symbolic Tensor (IteratorGetNext:1) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n    \n    \n    Call arguments received:\n      • x=('tf.Tensor(shape=(None, 8), dtype=float32)', 'tf.Tensor(shape=(None, 1), dtype=float32)')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=38'>39</a>\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=41'>42</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=42'>43</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mAdam(),  \u001b[39m# SGD(learning_rate=sgd_lr, momentum=momentum, nesterov=True),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=43'>44</a>\u001b[0m     loss\u001b[39m=\u001b[39mloss,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=44'>45</a>\u001b[0m     metrics\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mBinaryAccuracy(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=45'>46</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=47'>48</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=48'>49</a>\u001b[0m     x\u001b[39m=\u001b[39;49m[X, t],  \u001b[39m# [data[\"x\"], data[\"t\"]],\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=49'>50</a>\u001b[0m     y\u001b[39m=\u001b[39;49my,  \u001b[39m# data['y'],\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=50'>51</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49madam_callbacks,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=51'>52</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49mval_split,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=52'>53</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=53'>54</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=54'>55</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=55'>56</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=57'>58</a>\u001b[0m clear_output()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/production.ipynb#ch0000006?line=59'>60</a>\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mbinary_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1126'>1127</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1127'>1128</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1128'>1129</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1129'>1130</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1130'>1131</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    NotImplementedError: Exception encountered when calling layer \"tar_net\" (type tarNET).\n    \n    in user code:\n    \n        File \"/Users/arnaudpetit/Documents/Programmation/MIT/continuous_treatment/tarNET/models/tarNET.py\", line 76, in call  *\n            treatment_cat = tf.cast(\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\", line 2772, in transform  *\n            X = self._check_inputs(X, in_fit=False, copy=self.copy)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\", line 2702, in _check_inputs  *\n            X = self._validate_data(X, reset=in_fit,\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/base.py\", line 420, in _validate_data  *\n            X = check_array(X, **check_params)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in inner_f  *\n            return f(*args, **kwargs)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 673, in check_array  *\n            array = np.asarray(array, order=order, dtype=dtype)\n        File \"/Users/arnaudpetit/mambaforge/lib/python3.9/site-packages/numpy/core/_asarray.py\", line 83, in asarray  **\n            return array(a, dtype, copy=False, order=order)\n    \n        NotImplementedError: Cannot convert a symbolic Tensor (IteratorGetNext:1) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n    \n    \n    Call arguments received:\n      • x=('tf.Tensor(shape=(None, 8), dtype=float32)', 'tf.Tensor(shape=(None, 1), dtype=float32)')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "val_split = 0.2\n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "i = 0\n",
    "tf.random.set_seed(i)\n",
    "np.random.seed(i)\n",
    "\n",
    "sgd_callbacks = [\n",
    "    TerminateOnNaN(),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=40, min_delta=0.0),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"loss\",\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=verbose,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0,\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "adam_callbacks = [\n",
    "    TerminateOnNaN(),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20, min_delta=0.0),\n",
    "]\n",
    "\n",
    "# optimzier hyperparameters\n",
    "sgd_lr = 1e-5\n",
    "momentum = 0.9\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),  # SGD(learning_rate=sgd_lr, momentum=momentum, nesterov=True),\n",
    "    loss=loss,\n",
    "    metrics=tf.keras.metrics.BinaryAccuracy(),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[X, t],  # [data[\"x\"], data[\"t\"]],\n",
    "    y=y,  # data['y'],\n",
    "    callbacks=adam_callbacks,\n",
    "    validation_split=val_split,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "\n",
    "acc = history.history[\"binary_accuracy\"]\n",
    "val_acc = history.history[\"val_binary_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11981, 1), dtype=int32, numpy=\n",
       "array([[4],\n",
       "       [3],\n",
       "       [5],\n",
       "       ...,\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_cat = tf.cast(scaler.transform(t) * (9), tf.int32)\n",
    "treatment_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[-0.82223016,  0.3449639 , -0.12575623],\n",
       "       [ 0.5016385 , -0.96860427, -0.46677873],\n",
       "       [ 2.0880806 ,  2.5090044 , -0.4480631 ],\n",
       "       [ 0.0569069 , -0.00342684, -1.7664938 ],\n",
       "       [ 0.4463921 ,  0.74810964, -1.4654588 ],\n",
       "       [ 0.6412715 ,  0.05723069,  1.4187601 ],\n",
       "       [ 1.0584769 , -0.57483643,  0.33001095],\n",
       "       [ 0.20358515, -2.3415418 , -0.95508343],\n",
       "       [-0.53358316,  1.0723833 ,  0.02041745],\n",
       "       [-0.2298816 , -0.34991977,  0.806119  ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal((10,2))\n",
    "y = tf.random.normal((10,1))\n",
    "\n",
    "\n",
    "tf.keras.layers.Concatenate()([x, y])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56faac8612633bcfddb99da3ad5a50bcd343e3e14a61b03833611d8357de7104"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
